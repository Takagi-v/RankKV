# RankKV: åŸºäºAttentionçŸ©é˜µæœ‰æ•ˆç§©çš„KV Cacheå‹ç¼©æ–¹æ³•

## é¡¹ç›®æ–¹æ¡ˆè®¡åˆ’ä¹¦

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 èƒŒæ™¯

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†æ—¶éœ€è¦å­˜å‚¨KV Cacheæ¥é¿å…é‡å¤è®¡ç®—ï¼Œä½†KV Cacheçš„å¤§å°éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼Œæˆä¸ºæ¨ç†æ•ˆç‡çš„ä¸»è¦ç“¶é¢ˆã€‚ç°æœ‰çš„KV Cacheå‹ç¼©æ–¹æ³•é€šå¸¸å¯¹æ¯å±‚é‡‡ç”¨ç›¸åŒçš„å‹ç¼©ç­–ç•¥ï¼Œå¿½ç•¥äº†ä¸åŒå±‚ä¹‹é—´çš„å·®å¼‚ã€‚

### 1.2 æ ¸å¿ƒè§‚å¯Ÿ

æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼š**ä¸åŒå±‚çš„AttentionçŸ©é˜µå…·æœ‰ä¸åŒçš„"æœ‰æ•ˆç§©"ï¼ˆEffective Rankï¼‰**ï¼Œè¿™åæ˜ äº†è¯¥å±‚attentionåˆ†å¸ƒçš„å¤æ‚ç¨‹åº¦ï¼š
- **æœ‰æ•ˆç§©ä½** â†’ Attentionåˆ†å¸ƒé›†ä¸­åœ¨å°‘æ•°tokenä¸Š â†’ å¯ä»¥æ¿€è¿›å‹ç¼©
- **æœ‰æ•ˆç§©é«˜** â†’ Attentionåˆ†å¸ƒåˆ†æ•£åœ¨å¤šä¸ªtokenä¸Š â†’ éœ€è¦ä¿å®ˆå‹ç¼©

### 1.3 æ–¹æ³•æ¦‚è¿°

**RankKV** æ˜¯ä¸€ç§åŸºäºAttentionçŸ©é˜µæœ‰æ•ˆç§©çš„å±‚çº§è‡ªé€‚åº”KV Cacheå‹ç¼©æ–¹æ³•ï¼š
1. åœ¨Prefillé˜¶æ®µè®¡ç®—æ¯å±‚AttentionçŸ©é˜µçš„æœ‰æ•ˆç§©
2. æ ¹æ®æœ‰æ•ˆç§©ä¸ºæ¯å±‚åˆ†é…ä¸åŒçš„KV Cacheé¢„ç®—ï¼ˆbudgetï¼‰
3. ä½¿ç”¨ç°æœ‰çš„token selectionæ–¹æ³•ï¼ˆå¦‚SnapKVï¼‰é€‰æ‹©å…·ä½“ä¿ç•™å“ªäº›token

### 1.4 åˆ›æ–°ç‚¹

1. **é¦–æ¬¡æå‡ºä½¿ç”¨AttentionçŸ©é˜µçš„Effective RankæŒ‡å¯¼å±‚çº§budgetåˆ†é…**
2. **æ— è®­ç»ƒæ–¹æ³•**ï¼šåªéœ€åœ¨Prefillé˜¶æ®µè¿›è¡Œä¸€æ¬¡åˆ†æï¼Œä¸éœ€è¦é¢å¤–è®­ç»ƒ
3. **ä¸ç°æœ‰æ–¹æ³•æ­£äº¤**ï¼šå¯ä»¥ä¸ä»»ä½•token selectionæ–¹æ³•ç»“åˆ

---

## 2. æŠ€æœ¯æ–¹æ¡ˆ

### 2.1 æ•´ä½“æµç¨‹

```
è¾“å…¥æ–‡æœ¬ â†’ Prefillé˜¶æ®µ â†’ åˆ†æRank â†’ åˆ†é…Budget â†’ å‹ç¼©KV Cache â†’ Decodeé˜¶æ®µ â†’ è¾“å‡º
              â†“              â†“            â†“              â†“
         ç”ŸæˆAttentionçŸ©é˜µ  è®¡ç®—æ¯å±‚rank  æ ¹æ®rankåˆ†é…    é€‰æ‹©tokenå¹¶å‹ç¼©
         ç”ŸæˆKV Cache      (SVDåˆ†è§£)     æ¯å±‚budget      (ç”¨SnapKVç­‰)
```

### 2.2 Effective Rank è®¡ç®—

**å®šä¹‰**ï¼šç»™å®šä¸€ä¸ªçŸ©é˜µ $A$ï¼Œå…¶æœ‰æ•ˆç§©å®šä¹‰ä¸ºï¼š

$$\text{erank}(A) = \exp\left(-\sum_{i} \tilde{\sigma}_i \log \tilde{\sigma}_i\right)$$

å…¶ä¸­ $\tilde{\sigma}_i = \sigma_i / \sum_j \sigma_j$ æ˜¯å½’ä¸€åŒ–çš„å¥‡å¼‚å€¼ã€‚

**ç›´è§‚ç†è§£**ï¼š
- æœ‰æ•ˆç§©è¡¡é‡çŸ©é˜µ"ä¿¡æ¯ç»´åº¦"çš„å¤šå°‘
- å¦‚æœå¥‡å¼‚å€¼é›†ä¸­åœ¨å°‘æ•°å‡ ä¸ªï¼Œæœ‰æ•ˆç§©ä½
- å¦‚æœå¥‡å¼‚å€¼åˆ†æ•£åœ¨å¤šä¸ªï¼Œæœ‰æ•ˆç§©é«˜

**ä»£ç å®ç°**ï¼š

```python
import torch

def compute_effective_rank(matrix):
    """
    è®¡ç®—çŸ©é˜µçš„æœ‰æ•ˆç§©
    
    Args:
        matrix: [seq_len, seq_len] çš„AttentionçŸ©é˜µ
    
    Returns:
        effective_rank: float, æœ‰æ•ˆç§©å€¼
    """
    # SVDåˆ†è§£ï¼Œè·å–å¥‡å¼‚å€¼
    U, S, V = torch.svd(matrix)
    
    # å½’ä¸€åŒ–å¥‡å¼‚å€¼
    S_normalized = S / (S.sum() + 1e-10)
    
    # è®¡ç®—ç†µ
    entropy = -(S_normalized * torch.log(S_normalized + 1e-10)).sum()
    
    # æœ‰æ•ˆç§© = exp(ç†µ)
    effective_rank = torch.exp(entropy)
    
    return effective_rank.item()
```

### 2.3 Budget åˆ†é…ç­–ç•¥

**ç­–ç•¥**ï¼šæœ‰æ•ˆç§©é«˜çš„å±‚åˆ†é…æ›´å¤šbudgetï¼Œæœ‰æ•ˆç§©ä½çš„å±‚åˆ†é…æ›´å°‘budgetã€‚

```python
def allocate_budget(ranks, total_budget, min_budget=10):
    """
    æ ¹æ®æ¯å±‚çš„rankåˆ†é…budget
    
    Args:
        ranks: list, æ¯å±‚çš„æœ‰æ•ˆç§©
        total_budget: int, æ€»å…±è¦ä¿ç•™çš„tokenæ•°
        min_budget: int, æ¯å±‚æœ€å°‘ä¿ç•™çš„tokenæ•°
    
    Returns:
        budgets: list, æ¯å±‚åˆ†é…çš„budget
    """
    ranks_tensor = torch.tensor(ranks)
    
    # æŒ‰rankæ¯”ä¾‹åˆ†é…
    ratios = ranks_tensor / ranks_tensor.sum()
    budgets = (ratios * total_budget).int().tolist()
    
    # ç¡®ä¿æ¯å±‚è‡³å°‘æœ‰min_budget
    budgets = [max(b, min_budget) for b in budgets]
    
    return budgets
```

### 2.4 Token Selection

ä½¿ç”¨åŸºäºAttention Scoreçš„æ–¹æ³•é€‰æ‹©æ¯å±‚ä¿ç•™å“ªäº›tokenï¼š

```python
def select_tokens(K, V, attention_weights, budget):
    """
    åŸºäºattention scoreé€‰æ‹©è¦ä¿ç•™çš„token
    
    Args:
        K: [seq_len, head_dim], KeyçŸ©é˜µ
        V: [seq_len, head_dim], ValueçŸ©é˜µ
        attention_weights: [seq_len, seq_len], AttentionçŸ©é˜µ
        budget: int, è¦ä¿ç•™çš„tokenæ•°
    
    Returns:
        K_compressed, V_compressed: å‹ç¼©åçš„Kå’ŒV
        selected_indices: è¢«é€‰ä¸­çš„tokenç´¢å¼•
    """
    # ç”¨æœ€åå‡ ä¸ªtokençš„attentionä½œä¸ºè§‚å¯Ÿçª—å£
    window_size = min(32, attention_weights.shape[0])
    observation = attention_weights[-window_size:, :]  # [window, seq_len]
    
    # è®¡ç®—æ¯ä¸ªtokençš„é‡è¦æ€§åˆ†æ•°
    importance = observation.sum(dim=0)  # [seq_len]
    
    # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„budgetä¸ªtoken
    _, top_indices = torch.topk(importance, budget)
    top_indices = top_indices.sort().values  # ä¿æŒé¡ºåº
    
    # å‹ç¼©
    K_compressed = K[top_indices]
    V_compressed = V[top_indices]
    
    return K_compressed, V_compressed, top_indices
```

### 2.5 å®Œæ•´Pipeline

```python
class RankKV:
    def __init__(self, model, budget_ratio=0.3):
        """
        Args:
            model: HuggingFaceæ¨¡å‹
            budget_ratio: å‹ç¼©æ¯”ä¾‹ï¼Œ0.3è¡¨ç¤ºä¿ç•™30%çš„token
        """
        self.model = model
        self.budget_ratio = budget_ratio
    
    def compress(self, input_ids):
        """
        æ‰§è¡ŒRankKVå‹ç¼©
        
        Args:
            input_ids: [batch, seq_len], è¾“å…¥token ids
        
        Returns:
            compressed_kv_cache: å‹ç¼©åçš„KV Cache
        """
        seq_len = input_ids.shape[1]
        total_budget = int(seq_len * self.budget_ratio)
        
        # Step 1: Prefillï¼Œè·å–attentionçŸ©é˜µå’ŒKV cache
        with torch.no_grad():
            outputs = self.model(
                input_ids,
                output_attentions=True,
                use_cache=True
            )
        
        attentions = outputs.attentions      # tuple of [batch, heads, seq, seq]
        kv_cache = outputs.past_key_values   # tuple of (K, V)
        num_layers = len(attentions)
        
        # Step 2: è®¡ç®—æ¯å±‚çš„æœ‰æ•ˆç§©
        ranks = []
        for layer_idx in range(num_layers):
            # å¯¹æ‰€æœ‰headå–å¹³å‡
            attn = attentions[layer_idx].mean(dim=1).squeeze(0)  # [seq, seq]
            rank = compute_effective_rank(attn)
            ranks.append(rank)
        
        # Step 3: æ ¹æ®rankåˆ†é…budget
        budgets = allocate_budget(ranks, total_budget)
        
        # Step 4: å‹ç¼©æ¯å±‚çš„KV Cache
        compressed_kv_cache = []
        for layer_idx in range(num_layers):
            K, V = kv_cache[layer_idx]
            attn = attentions[layer_idx].mean(dim=1).squeeze(0)
            budget = budgets[layer_idx]
            
            K_comp, V_comp, _ = select_tokens(
                K.squeeze(0).squeeze(0),  # å»æ‰batchå’Œheadç»´åº¦è¿›è¡Œé€‰æ‹©
                V.squeeze(0).squeeze(0),
                attn,
                budget
            )
            compressed_kv_cache.append((K_comp, V_comp))
        
        return compressed_kv_cache, ranks, budgets
```

---

## 3. å®éªŒè®¾è®¡

### 3.1 å®éªŒç¯å¢ƒ

| é¡¹ç›® | é…ç½® |
|------|------|
| æ¨¡å‹ | Pythia-2.8B |
| æ•°æ®é›† | WikiText-2, PG-19 |
| GPU | æ ¹æ®å®é™…æƒ…å†µ |
| æ¡†æ¶ | PyTorch, HuggingFace Transformers |

### 3.2 è¯„æµ‹æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **PPL (Perplexity)** | è¯­è¨€æ¨¡å‹å›°æƒ‘åº¦ï¼Œè¶Šä½è¶Šå¥½ |
| **å‹ç¼©ç‡** | å‹ç¼©åKV Cacheå¤§å° / åŸå§‹å¤§å° |
| **æ¨ç†é€Ÿåº¦** | Tokens per second |
| **æ˜¾å­˜å ç”¨** | Peak GPU memory |

### 3.3 Baselineæ–¹æ³•

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| **Dense** | ä¸å‹ç¼©ï¼Œä½œä¸ºæ€§èƒ½ä¸Šç•Œ |
| **StreamingLLM** | ä¿ç•™sink tokens + recent tokens |
| **SnapKV** | åŸºäºattention scoreé€‰æ‹©tokenï¼Œæ¯å±‚ç›¸åŒbudget |
| **PyramidKV** | é‡‘å­—å¡”å½¢çŠ¶çš„å›ºå®šbudgetåˆ†é… |
| **RankKV (Ours)** | åŸºäºæœ‰æ•ˆç§©çš„è‡ªé€‚åº”budgetåˆ†é… |

### 3.4 å®éªŒåˆ—è¡¨

#### å®éªŒ1ï¼šåˆ†æå®éªŒï¼ˆéªŒè¯ä½ç§©æ€§å­˜åœ¨ï¼‰

**ç›®çš„**ï¼šå±•ç¤ºPythia-2.8Bå„å±‚AttentionçŸ©é˜µçš„æœ‰æ•ˆç§©åˆ†å¸ƒ

**å†…å®¹**ï¼š
- åœ¨WikiText-2ä¸Šé‡‡æ ·å¤šä¸ªæ–‡æœ¬
- è®¡ç®—æ¯å±‚çš„å¹³å‡æœ‰æ•ˆç§©
- ç»˜åˆ¶ Layer vs Effective Rank å›¾

**é¢„æœŸè¾“å‡º**ï¼š
- å›¾è¡¨ï¼šå„å±‚æœ‰æ•ˆç§©åˆ†å¸ƒ
- å‘ç°ï¼šä¸åŒå±‚ç¡®å®æœ‰ä¸åŒçš„æœ‰æ•ˆç§©

#### å®éªŒ2ï¼šä¸»å®éªŒï¼ˆå¯¹æ¯”å„æ–¹æ³•ï¼‰

**ç›®çš„**ï¼šå¯¹æ¯”RankKVä¸baselineæ–¹æ³•çš„æ€§èƒ½

**è®¾ç½®**ï¼š
- å‹ç¼©ç‡ï¼š30%, 50%, 70%
- æ•°æ®é›†ï¼šWikiText-2, PG-19

**è¾“å‡º**ï¼š

| Method | WikiText-2 PPL | PG-19 PPL | å‹ç¼©ç‡ |
|--------|----------------|-----------|--------|
| Dense | - | - | 100% |
| StreamingLLM | - | - | 30% |
| SnapKV | - | - | 30% |
| PyramidKV | - | - | 30% |
| **RankKV** | - | - | 30% |

#### å®éªŒ3ï¼šAblation Study

**ç›®çš„**ï¼šéªŒè¯å„ç»„ä»¶çš„è´¡çŒ®

**å¯¹æ¯”**ï¼š
1. RankKV (å®Œæ•´æ–¹æ³•)
2. Uniform Budget (æ¯å±‚ç›¸åŒbudget)
3. Random Budget (éšæœºåˆ†é…budget)
4. Inverse RankKV (rankä½çš„å±‚åè€Œåˆ†é…æ›´å¤šbudget)

#### å®éªŒ4ï¼šå¯è§†åŒ–åˆ†æ

**å†…å®¹**ï¼š
- å„å±‚æœ‰æ•ˆç§©åˆ†å¸ƒæŸ±çŠ¶å›¾
- Budgetåˆ†é…å¯¹æ¯”å›¾ï¼ˆRankKV vs PyramidKV vs Uniformï¼‰
- PPL vs å‹ç¼©ç‡æ›²çº¿
- ä¸åŒåºåˆ—é•¿åº¦ä¸‹çš„rankå˜åŒ–

---

## 4. ä»£ç ç»“æ„

```
rankkv/
â”œâ”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ requirements.txt          # ä¾èµ–
â”œâ”€â”€ rankkv/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rank_analysis.py      # æœ‰æ•ˆç§©è®¡ç®—
â”‚   â”œâ”€â”€ budget_allocation.py  # Budgetåˆ†é…
â”‚   â”œâ”€â”€ token_selection.py    # Tokené€‰æ‹©
â”‚   â”œâ”€â”€ compression.py        # KV Cacheå‹ç¼©
â”‚   â””â”€â”€ pipeline.py           # å®Œæ•´pipeline
â”œâ”€â”€ baselines/
â”‚   â”œâ”€â”€ streaming_llm.py
â”‚   â”œâ”€â”€ snapkv.py
â”‚   â””â”€â”€ pyramidkv.py
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ analysis.py           # å®éªŒ1ï¼šåˆ†æå®éªŒ
â”‚   â”œâ”€â”€ main_exp.py           # å®éªŒ2ï¼šä¸»å®éªŒ
â”‚   â”œâ”€â”€ ablation.py           # å®éªŒ3ï¼šæ¶ˆèå®éªŒ
â”‚   â””â”€â”€ visualization.py      # å®éªŒ4ï¼šå¯è§†åŒ–
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_analysis.sh
â”‚   â”œâ”€â”€ run_main_exp.sh
â”‚   â””â”€â”€ run_ablation.sh
â””â”€â”€ results/
    â”œâ”€â”€ figures/
    â””â”€â”€ tables/
```

---

## 5. åˆ†å·¥å®‰æ’

### 5.1 æˆå‘˜åˆ†å·¥

| æˆå‘˜ | èŒè´£ | å…·ä½“ä»»åŠ¡ | å·¥ä½œé‡ |
|------|------|----------|--------|
| **æˆå‘˜A** | ç®—æ³•å®ç° | æ ¸å¿ƒä»£ç å¼€å‘ã€Pipelineæ­å»ºã€Debug | 40% |
| **æˆå‘˜B** | å®éªŒè¿è¡Œ | è·‘å®éªŒã€æ”¶é›†æ•°æ®ã€åˆ¶ä½œå›¾è¡¨ | 35% |
| **æˆå‘˜C** | è®ºæ–‡æ’°å†™ | å†™è®ºæ–‡ã€åˆ¶ä½œç¤ºæ„å›¾ã€æ•´ç†ä»“åº“ | 25% |

### 5.2 è¯¦ç»†ä»»åŠ¡åˆ†é…

#### æˆå‘˜Aï¼šç®—æ³•å®ç°

**Week 1**:
- [ ] æ­å»ºé¡¹ç›®æ¡†æ¶
- [ ] å®ç° `compute_effective_rank()` å‡½æ•°
- [ ] å®ç° `allocate_budget()` å‡½æ•°
- [ ] å®ç° `select_tokens()` å‡½æ•°
- [ ] å®ç°å®Œæ•´çš„ `RankKV` ç±»

**Week 2**:
- [ ] å®ç°baselineæ–¹æ³•ï¼ˆStreamingLLM, SnapKV, PyramidKVï¼‰
- [ ] Debugå’Œä¼˜åŒ–
- [ ] ååŠ©æˆå‘˜Bè·‘å®éªŒ

#### æˆå‘˜Bï¼šå®éªŒè¿è¡Œ

**Week 1**:
- [ ] é…ç½®å®éªŒç¯å¢ƒ
- [ ] ä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†
- [ ] è·‘Dense baseline
- [ ] è·‘StreamingLLMã€SnapKVã€PyramidKV baseline

**Week 2**:
- [ ] è·‘RankKVä¸»å®éªŒ
- [ ] è·‘Ablationå®éªŒ
- [ ] æ•´ç†æ‰€æœ‰æ•°æ®ï¼Œåˆ¶ä½œè¡¨æ ¼
- [ ] åˆ¶ä½œå›¾è¡¨ï¼ˆmatplotlib/seabornï¼‰

#### æˆå‘˜Cï¼šè®ºæ–‡æ’°å†™

**Week 1**:
- [ ] é˜…è¯»ç›¸å…³è®ºæ–‡ï¼Œæ•´ç†Related Work
- [ ] æ’°å†™Introductionåˆç¨¿
- [ ] æ’°å†™Methodåˆç¨¿
- [ ] åˆ¶ä½œæ–¹æ³•ç¤ºæ„å›¾

**Week 2**:
- [ ] æ ¹æ®å®éªŒç»“æœæ’°å†™Experimentséƒ¨åˆ†
- [ ] æ’°å†™Abstractå’ŒConclusion
- [ ] æ•´ç†GitHubä»“åº“ï¼Œå†™README
- [ ] è®ºæ–‡æ¶¦è‰²

### 5.3 æ—¶é—´çº¿

```
Week 1 (Day 1-7):
â”œâ”€â”€ Day 1-2: Aæ­å»ºæ¡†æ¶, Bé…ç¯å¢ƒ, Cè¯»è®ºæ–‡
â”œâ”€â”€ Day 3-4: Aå®ç°æ ¸å¿ƒå‡½æ•°, Bè·‘baseline, Cå†™Intro
â”œâ”€â”€ Day 5-7: Aå®ŒæˆPipeline, Bå®Œæˆbaseline, Cå†™Method

Week 2 (Day 8-14):
â”œâ”€â”€ Day 8-10: Aå®ç°baseline+debug, Bè·‘ä¸»å®éªŒ, Cæ ¹æ®ç»“æœå†™Exp
â”œâ”€â”€ Day 11-12: Aä¼˜åŒ–ä»£ç , Bè·‘Ablation+åšå›¾, Cå†™Abstract/Conclusion
â”œâ”€â”€ Day 13-14: å…¨å‘˜æ•´åˆã€æ£€æŸ¥ã€æäº¤
```

---

## 6. è®ºæ–‡ç»“æ„

### 6.1 å¤§çº²ï¼ˆ4é¡µ NeurIPSæ ¼å¼ï¼‰

```
Abstract (0.3é¡µ)
- é—®é¢˜ï¼šKV Cacheæ˜¯LLMæ¨ç†ç“¶é¢ˆ
- è§‚å¯Ÿï¼šä¸åŒå±‚AttentionçŸ©é˜µæœ‰æ•ˆç§©ä¸åŒ
- æ–¹æ³•ï¼šRankKVï¼ŒåŸºäºæœ‰æ•ˆç§©çš„è‡ªé€‚åº”å‹ç¼©
- ç»“æœï¼šåœ¨Pythia-2.8Bä¸Šä¼˜äºbaseline

1. Introduction (0.8é¡µ)
- 1.1 èƒŒæ™¯ï¼šLLMæ¨ç†æ•ˆç‡é—®é¢˜
- 1.2 ç°æœ‰æ–¹æ³•å±€é™ï¼šå›ºå®šå‹ç¼©ç­–ç•¥å¿½ç•¥å±‚é—´å·®å¼‚
- 1.3 æˆ‘ä»¬çš„è§‚å¯Ÿï¼šæœ‰æ•ˆç§©åæ˜ å±‚çš„å‹ç¼©éœ€æ±‚
- 1.4 è´¡çŒ®ï¼š(1)é¦–æ¬¡ç”¨æœ‰æ•ˆç§©æŒ‡å¯¼å‹ç¼© (2)æ— è®­ç»ƒæ–¹æ³• (3)ä¸ç°æœ‰æ–¹æ³•æ­£äº¤

2. Method (1.2é¡µ)
- 2.1 Preliminariesï¼šKV Cacheå’Œå‹ç¼©
- 2.2 Effective Rankåˆ†æ
- 2.3 Rank-guided Budget Allocation
- 2.4 ç®—æ³•æµç¨‹ï¼ˆé…ä¼ªä»£ç å’Œç¤ºæ„å›¾ï¼‰

3. Experiments (1.5é¡µ)
- 3.1 å®éªŒè®¾ç½®ï¼ˆæ¨¡å‹ã€æ•°æ®ã€baselineã€æŒ‡æ ‡ï¼‰
- 3.2 ä¸»å®éªŒç»“æœï¼ˆè¡¨æ ¼ï¼‰
- 3.3 Ablation Study
- 3.4 åˆ†æä¸è®¨è®º

4. Conclusion (0.2é¡µ)
- æ€»ç»“è´¡çŒ®
- å±€é™æ€§å’Œæœªæ¥å·¥ä½œ

References
```

### 6.2 å…³é”®å›¾è¡¨

1. **Figure 1**: RankKVæ•´ä½“æ¡†æ¶å›¾
2. **Figure 2**: å„å±‚æœ‰æ•ˆç§©åˆ†å¸ƒ
3. **Figure 3**: Budgetåˆ†é…å¯¹æ¯”ï¼ˆRankKV vs PyramidKV vs Uniformï¼‰
4. **Table 1**: ä¸»å®éªŒç»“æœå¯¹æ¯”
5. **Table 2**: Ablationå®éªŒç»“æœ

---

## 7. å‚è€ƒæ–‡çŒ®

æ ¸å¿ƒå‚è€ƒï¼š
1. StreamingLLM: Efficient Streaming Language Models with Attention Sinks
2. SnapKV: LLM Knows What You Are Looking For Before Generation
3. PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling
4. DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs
5. Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation

æœ‰æ•ˆç§©å‚è€ƒï¼š
6. Roy & Vetterli (2007): "The Effective Rank: A Measure of Effective Dimensionality"

---

## 8. é£é™©ä¸åº”å¯¹

| é£é™© | åº”å¯¹ç­–ç•¥ |
|------|----------|
| å„å±‚rankå·®å¼‚ä¸æ˜æ˜¾ | å¦‚å®æŠ¥å‘Šï¼Œåˆ†æåŸå› ï¼Œè¿™æœ¬èº«ä¹Ÿæ˜¯å‘ç° |
| æ€§èƒ½æå‡ä¸æ˜æ˜¾ | ä½œä¸šè¦æ±‚"ä¸è¿½æ±‚é«˜æ€§èƒ½"ï¼Œé‡ç‚¹æ”¾åœ¨åˆ†æ |
| SVDè®¡ç®—å¼€é”€å¤§ | åªåœ¨Prefillåšä¸€æ¬¡ï¼Œå¯æ¥å— |
| ä»£ç bug | é¢„ç•™debugæ—¶é—´ï¼Œå¢é‡æµ‹è¯• |
| æ—¶é—´ä¸å¤Ÿ | ä¼˜å…ˆä¿è¯æ ¸å¿ƒå®éªŒï¼Œç æ‰éƒ¨åˆ†Ablation |

---

## 9. Checklist

### æäº¤å‰æ£€æŸ¥

- [ ] ä»£ç å¯è¿è¡Œï¼Œç»“æœå¯å¤ç°
- [ ] READMEæ¸…æ™°ï¼ŒåŒ…å«è¿è¡Œè¯´æ˜
- [ ] è®ºæ–‡æ ¼å¼æ­£ç¡®ï¼ˆNeurIPSæ¨¡æ¿ï¼Œâ‰¤4é¡µï¼‰
- [ ] æ‰€æœ‰å›¾è¡¨æ¸…æ™°ã€æœ‰æ ‡æ³¨
- [ ] å‚è€ƒæ–‡çŒ®å®Œæ•´
- [ ] åˆ†å·¥è¯´æ˜å·²åŒ…å«åœ¨è®ºæ–‡ä¸­
- [ ] GitHubä»“åº“å…¬å¼€

---

**ç¥é¡¹ç›®é¡ºåˆ©ï¼ğŸš€**